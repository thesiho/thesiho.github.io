<!DOCTYPE html>

<html lang="en">
    <head>

        <!-- Metadata -->
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/>
        <meta name="description" content="website"/>
        <meta name="author" content="khang nguyen"/>
        <title>DeepGiraffe | PhD @ KAIST, Now @ SAIT, Samsung Electronics</title>
        <link rel="icon" type="image/x-icon" href="assets/img/giraffe_icon.png"/>
        
        <!-- Font Awesome icons -->
        <script src="https://use.fontawesome.com/releases/v5.15.3/js/all.js"></script>
		
        <!-- Google fonts-->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">        
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css"/>
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css"/>
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.carousel.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.theme.default.min.css">

        <!-- Core theme CSS -->
        <link href="styles/styles.css" rel="stylesheet"/>

    </head>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <body class="light-theme">

        <!-- Moving particles -->
        <canvas id="canvas"></canvas>

        <!-- Progress bar on top -->
        <div class="progress-bar-container">
            <div class="progress-bar" id="progressBar"></div>
        </div>

        <!-- Back to top button -->
        <a id="back-to-top-button"></a>

        <!-- Toggle dark/light theme button -->
        <button class="toggle-theme-button" onclick="toggleTheme()">â˜€ï¸</button>
        
        <!-- Assitant icon saying about theme changes -->
        <div class="popup-icon-container" id="popupIconContainer" draggable="true">
            <div class="icon"><img src="assets/img/giraffe_icon.png" width="65" height="65"></div>
            <div class="speech-balloon"></div>
        </div>
        
        <!-- Dismissal area for assistant icon -->
        <div class="dismissal-area" id="dismissalArea">&#10006;</div>

        <!-- Content -->
        <div class="container mt-5">
            <!-- About section -->

<div class="row mb-4">
    <div class="col-lg-2 col-md-4">
        <div class="ring-container">
            <div class="ring">
                <div class="hollow-ring">
                    <img class="profile-image" src="assets/img/new_pic.jpg" alt="Giraffe AI Researcher" />
                    
                </div>
            </div>
        </div>
        <hr />
        <div class="social-icons">	
             <a class="social-icon" href="https://scholar.google.com/citations?user=E_QibGEAAAAJ&amp;hl=en&amp;oi=sraJ" target="_blank" rel="noopener" title="Google Scholar"><i class="fa fa-graduation-cap" style="font-size: 35px; color: #4285f4"></i></a> 
            
            
            
            
        </div>
        <p></p>
    </div>

    <div class="col-lg-10 col-md-8">
        <h2>Giraffe AI Researcher </h2>
        <p></p>
        ì‚¼ì„±ì¢…í•©ê¸°ìˆ ì› Computer Vision researcher &amp; në…„ì°¨ ê³¨í¼ &amp; <a href="https://thesiho.kr" target="_blank" rel="noopener">ì‹œí˜¸í•œì˜ì›</a> ë¬´ì„ê¸ˆì§ì›(?!) ìœ¼ë¡œ ì§€ë‚´ê³  ìˆìŠµë‹ˆë‹¤.
        <p></p>
              
        <p></p>
        <code>&gt;&gt; Multi Modal Foundation Model, Large Language Model, Visual Object Tracking, NeRF, Generative model, 3D perception, Light-weighted ML, Medical imaging (MRI recon.), Signal processing</code>
        <!-- <p></p> -->
    </div>
</div>

<!-- Updates section -->

<hr />

<div class="row" id="updates">
    <div class="col">
        <h2 clss="mb-5">ğŸ–‡ï¸ updates</h2>
        <p></p>
        <div class="owl-carousel owl-theme">
            
                <div class="news-card">
    <img src="assets/img/update_siho.jpg" class="w-full rounded-lg" />
    <div class="news-desc">Grand opening of  <hightlight>ì‹œí˜¸í•œì˜ì›</hightlight>.</div>
    <div class="news-time">March 2024</div>
</div>
            
        </div>
        <p></p>
    </div>
</div>

<!-- Research section -->

<hr />

<div class="row" id="dlstudy">
    <div class="col">
        <h2 clss="mb-5"> ğŸ–‡ï¸ Deep learning studies</h2>
        <p></p>
        <div id="filters">
            <button class="filter-button active" data-filter="*">all</button>
            
        </div>
        <p></p>
        <div id="projects" class="isotope">
            
        </div>
        <p></p>
        <p id="markdown-container"></p>
    </div>
</div>

<!-- Research section -->

<hr />

<div class="row" id="research">
    <div class="col">
        <h2 clss="mb-5">ğŸ–‡ï¸ publications</h2>
        <p></p>
        <div id="filters">
            <button class="filter-button active" data-filter="*">all</button>
            
                <button class="filter-button" data-filter="generative model">generative model</button>
            
                <button class="filter-button" data-filter="light-weight">light-weight</button>
            
        </div>
        <p></p>
        <div id="projects" class="isotope">
            
                <div class="project" data-filter="light-weight">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/RasCaNet.jpg" />
        </div>
        <div class="col-sm-8">
            
            <b>RaScaNet Learning Tiny Models by Raster-Scanning Images</b>
            <br />
            <i><a href="https://openaccess.thecvf.com" target="_blank" rel="noopener">CVPR2021</a></i> 
             <b style="color: #e74d3c">[Accepted]</b> 
            <br />
            J Yoo, <u>Me</u>, et al
            <br />
             <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yoo_RaScaNet_Learning_Tiny_Models_by_Raster-Scanning_Images_CVPR_2021_paper.pdf" target="_blank" rel="noopener">[PDF]</a> 
             | <a href="https://github.com/SAITPublic/rascanet" target="_blank" rel="noopener">[CODE]</a> 
            
            
            
            <br />
            <u><b><i>Abstract</i></b>:</u> 
            Deploying deep convolutional neural networks on ultra-low power systems is challenging due to the extremely limited resources. Especially, the memory becomes a bottleneck as the systems put a hard limit on the size of on-chip memory. Because peak memory explosion in the lower layers is critical even in tiny models, the size of an input image should be reduced with sacrifice in accuracy.
            <span class="collapse" id="light-weight">
                To overcome this drawback, we propose a novel Raster-Scanning Network, named RaScaNet, inspired by raster-scanning in image sensors. RaScaNet reads only a few rows of pixels at a time using a convolutional neural network and then sequentially learns the representation of the whole image using a recurrent neural network. The proposed method operates on an ultra-low power system without input size reduction; it requires 15.9-24.3x smaller peak memory and 5.3-12.9x smaller weight memory than the state-of-the-art tiny models. Moreover, RaScaNet fully exploits on-chip SRAM and cache memory of the system as the sum of the peak memory and the weight memory does not exceed 60 KB, improving the power efficiency of the system. In our experiments, we demonstrate the binary classification performance of RaScaNet on Visual Wake Words and Pascal VOC datasets.
            </span> 
            <span> <a href="#light-weight" data-toggle="collapse" onclick="toggleText(this)" id="link-light-weight">... See More</a></span>
        </div>                       
    </div>
</div>

            
                <div class="project" data-filter="generative model">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/NMI_Colla.jpg" />
        </div>
        <div class="col-sm-8">
            
            <b>Assessing the importance of magnetic resonance contrasts using collaborative generative adversarial networks</b>
            <br />
            <i><a href="https://www.nature.com/articles/s42256-019-0137-x" target="_blank" rel="noopener">Nature Machine Intelligence 2020</a></i> 
             <b style="color: #e74d3c">[Accepted]</b> 
            <br />
            <u>Me</u>, et al
            <br />
            
            
            
            
            
            <br />
            <u><b><i>Abstract</i></b>:</u> 
            A unique advantage of magnetic resonance imaging (MRI) is its mechanism for generating various image contrasts depending on tissue-specific parameters, which provides useful clinical information. Unfortunately, a complete set of MR contrasts is often difficult to obtain in a real clinical environment.
            <span class="collapse" id="generative model">
                Recently, there have been claims that generative models such as generative adversarial networks (GANs) can synthesize MR contrasts that are not acquired. However, the poor scalability of existing GAN-based image synthesis poses a fundamental challenge to understanding the nature of MR contrasts "which contrasts matter, and which cannot be synthesized by generative models?" Here, we show that these questions can be addressed systematically by learning the joint manifold of multiple MR contrasts using collaborative generative adversarial networks. Our experimental results show that the exogenous contrast provided by contrast agents is not replaceable, but endogenous contrasts such as T1 and T2 can be synthesized from other contrasts. These findings provide important guidance for the acquisition-protocol design of MR in clinical environments.
            </span> 
            <span> <a href="#generative model" data-toggle="collapse" onclick="toggleText(this)" id="link-generative model">... See More</a></span>
        </div>                       
    </div>
</div>

            
                <div class="project" data-filter="generative model">
    <div class="row mb-4">
        <div class="col-sm-4">
            <img width="100%" height="auto" class="w-full rounded-lg" src="assets/img/CollaGAN.jpg" />
        </div>
        <div class="col-sm-8">
            
            <b>CollaGAN Collaborative GAN for Missing Image Data Imputation</b>
            <br />
            <i><a href="https://openaccess.thecvf.com" target="_blank" rel="noopener">CVPR2019</a></i> 
             <b style="color: #e74d3c">[Oral presentation]</b> 
            <br />
            <u>Me</u>, et al.
            <br />
             <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_CollaGAN_Collaborative_GAN_for_Missing_Image_Data_Imputation_CVPR_2019_paper.html" target="_blank" rel="noopener">[PDF]</a> 
             | <a href="https://github.com/ltntdw/tf_CollaGAN" target="_blank" rel="noopener">[CODE]</a> 
            
            
            
            <br />
            <u><b><i>Abstract</i></b>:</u> 
            In many applications requiring multiple inputs to obtain a desired output, if any of the input data is missing, it often introduces large amounts of bias. Although many techniques have been developed for imputing missing data, the image imputation is still difficult due to complicated nature of natural images.
            <span class="collapse" id="generative model">
                To address this problem, here we proposed a novel framework for missing image data imputation, called Collaborative Generative Adversarial Network (CollaGAN). CollaGAN convert the image imputation problem to a multi-domain images-to-image translation task so that a single generator and discriminator network can successfully estimate the missing data using the remaining clean data set. We demonstrate that CollaGAN produces the images with a higher visual quality compared to the existing competing approaches in various image imputation tasks.
            </span> 
            <span> <a href="#generative model" data-toggle="collapse" onclick="toggleText(this)" id="link-generative model">... See More</a></span>
        </div>                       
    </div>
</div>

            
        </div>
        <p></p>
    </div>
</div>

<!-- Gallery section -->

<hr />

<div class="row" id="gallery">
    <div class="col">
        <h2 clss="mb-5">ğŸ–‡ï¸ gallery</h2>
        <p></p>
        AI ì´ì™¸ì˜ ì‚¬ëŠ” ì´ì•¼ê¸°
        <p></p>
        
            <div class="gallery">
    <img src="assets/memo/siho_open.jpg" alt="ì—¬ìì¹œêµ¬ê°€ ë™íƒ„ì— ê°œì›ì„ í–ˆì–´ìš”!" width="800" height="600" />
    <div class="desc">ì—¬ìì¹œêµ¬ê°€ ë™íƒ„ì— ê°œì›ì„ í–ˆì–´ìš”! (2024)</div>
</div>

        
        <p></p>
    </div>
</div>

<!-- Footer section -->

<div>â€</div>
<hr />

<footer class="pt-2 my-md-2 pt-md-">
    <div class="row justify-content-center">
        <div class="col-7 col-md text-left align-self-center">
            <p class="h6">Â© DeepGiraffe, <span id="currentYear"></span></p>
            <a href="https://github.com/mkhangg/academic-website" target="_blank" rel="noopener"><b>&gt; web source @github</b></a>
        </div>
        <div class="col col-md text-right">
            
                <img class="mr+4" src="assets/img/logo.jpg" data-canonical-src="assets/img/logo.jpg" alt="Giraffe" width="60" />
            
        </div>
    </div>
    <p></p>
</footer>


        </div>

        <!-- Bootstrap core JS-->
        <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"></script>

        <!-- Isotope JS -->
        <script src="https://cdn.jsdelivr.net/npm/isotope-layout@3.0.2/dist/isotope.pkgd.min.js"></script>

        <!-- OwlCarousel2 JS -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/owl.carousel.min.js"></script>
        
		<!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script>

		<!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    <script>
       document.addEventListener('DOMContentLoaded', function () {
         const markdownPath = '/_posts/2024-03-23-init.markdown'; // Markdown íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”
         const xhr = new XMLHttpRequest();
         xhr.open('GET', markdownPath, true);
         xhr.onreadystatechange = function () {
           if (xhr.readyState === 4 && xhr.status === 200) {
             const markdownContent = xhr.responseText;
             const htmlContent = marked.parse(markdownContent);
             document.getElementById('markdown-container').innerHTML = htmlContent;
           }
         };
         xhr.send();
       });
    </script>

    </body>
</html>
